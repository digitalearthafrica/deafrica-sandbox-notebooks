{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "# Landsat Vegetation Phenology\n",
    "\n",
    "<hr>\n",
    "\n",
    "*Notebook compatible with DE Africa Collection 1 Sandbox\n",
    "\n",
    "# Notebook Summary\n",
    "\n",
    "This notebook calculates vegetation phenology changes using Landsat 7 or Landsat 8 data. To detect changes in plant life for Landsat, the algorithm uses either the Normalized Difference Vegetation Index (NDVI) or the Enhanced Vegetation Index (EVI), which are common proxies for vegetation growth and health. The outputs of this notebook can be used to assess differences in agriculture fields over time or space and also allow the assessment of growing states such as planting and harvesting.  \n",
    "<br>\n",
    "There are two output products. The first output product is a time series boxplot of NDVI or EVI with the data potentially binned by week, month, week of year, or month of year. The second output product is a time series lineplot of the mean NDVI or EVI for each year, with the data potentially binned by week or month. This product is useful for comparing years to each other.\n",
    "<br><br>\n",
    "See this website for more information: https://phenology.cr.usgs.gov/ndvi_foundation.php\n",
    "\n",
    "<hr>\n",
    "\n",
    "# Index\n",
    "\n",
    "* [Import Dependencies and Connect to the Data Cube](#import)\n",
    "* [Choose Platforms and Products](#plat_prod)\n",
    "* [Define the Extents of the Analysis](#define_extents)\n",
    "* [Load Data from the Data Cube and Obtain the Vegetation Proxy](#load_data)\n",
    "* [Create Phenology Products](#phenology_products)\n",
    "    * [Plot the Vegetation Index Over Time in a Box-and-Whisker Plot](#phenology_plot_1)\n",
    "    * [Plot the Vegetation Index Over Time for Each Year](#phenology_plot_2)\n",
    "* [Export Curve Fits to a CSV File](#export)\n",
    "* [Show TIMESAT Stats](#timesat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"import\">Import Dependencies and Connect to the Data Cube [&#9652;](#top)</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacube\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Supress Warnings.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from odc.ui import DcViewer\n",
    "from datacube.helpers import write_geotiff\n",
    "\n",
    "\n",
    "#import DE Africa script\n",
    "sys.path.append('../../Scripts')\n",
    "from deafrica_plotting import display_map\n",
    "from deafrica_plotting import rgb\n",
    "\n",
    "\n",
    "#import DCAL utility scripts\n",
    "sys.path.append('../DCAL_utils')\n",
    "from clean_mask import landsat_qa_clean_mask, landsat_clean_mask_invalid\n",
    "from sort import xarray_sortby_coord\n",
    "from vegetation import NDVI, EVI\n",
    "from plotter_utils import xarray_time_series_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app=\"DCAL Vegitation Phenology\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Extent of Avalible Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landsat 8 Products:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ALOS/ALOS-2</td>\n",
       "      <td>alos_palsar_mosaic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>None</td>\n",
       "      <td>ga_ls8c_gm_2_annual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>None</td>\n",
       "      <td>ga_ls8c_wofs_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>None</td>\n",
       "      <td>ga_ls8c_wofs_2_annual_summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>None</td>\n",
       "      <td>ga_ls8c_wofs_2_summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LANDSAT_5</td>\n",
       "      <td>ls5_usgs_sr_scene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LANDSAT_7</td>\n",
       "      <td>ls7_usgs_sr_scene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LANDSAT_8</td>\n",
       "      <td>ls8_usgs_sr_scene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>ls_usgs_fc_scene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>ls_usgs_wofs_scene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>None</td>\n",
       "      <td>ls_usgs_wofs_summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SENTINEL1</td>\n",
       "      <td>sentinel1_ghana_monthly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SRTM</td>\n",
       "      <td>srtm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       platform                           name\n",
       "id                                            \n",
       "14  ALOS/ALOS-2             alos_palsar_mosaic\n",
       "17         None            ga_ls8c_gm_2_annual\n",
       "15         None                 ga_ls8c_wofs_2\n",
       "13         None  ga_ls8c_wofs_2_annual_summary\n",
       "16         None         ga_ls8c_wofs_2_summary\n",
       "3     LANDSAT_5              ls5_usgs_sr_scene\n",
       "2     LANDSAT_7              ls7_usgs_sr_scene\n",
       "1     LANDSAT_8              ls8_usgs_sr_scene\n",
       "6          None               ls_usgs_fc_scene\n",
       "5          None             ls_usgs_wofs_scene\n",
       "11         None           ls_usgs_wofs_summary\n",
       "18    SENTINEL1        sentinel1_ghana_monthly\n",
       "12         SRTM                           srtm"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get available products\n",
    "products_info = dc.list_products()\n",
    "\n",
    "# List Landsat 8 products\n",
    "print(\"Landsat 8 Products:\")\n",
    "products_info[[\"platform\", \"name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97cabf515bde465cbaba4f04cbf7ec4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(layout=Layout(flex='0 1 auto', width='10em'), options=('ls8_usgs_sr_sceâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DcViewer(dc=dc,\n",
    "         products = ['ls8_usgs_sr_scene'],\n",
    "         time='2017',\n",
    "         center=(0.565, 38.007),\n",
    "         zoom=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"define_extents\">Define the Extents of the Analysis [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:red\";><b>CHANGE INPUTS BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an analysis region (Lat-Lon) within the extents listed above. \n",
    "# Select a time period (Min-Max) within the extents listed above (Year-Month-Day)\n",
    "\n",
    "# Tanzania Grassland / Cropland\n",
    "# lat = (-4.5074, -4.4860) # North of Swaga Game Reserve\n",
    "# lon = (35.1349, 35.1735) # North of Swaga Game Reserve\n",
    "\n",
    "# Tanzania Grassland / Cropland\n",
    "# lat = (-8.1541, -8.1272) # Southern Cropland \n",
    "# lon = (33.2016, 33.2545) # Southern Cropland\n",
    "\n",
    "# Aviv Coffee Farm, Tanzania (small)\n",
    "# lat = (-10.6999, -10.6959) \n",
    "# lon = (35.2608, 35.2662) \n",
    "\n",
    "# Aviv Coffee Farm, Tanzania (surrounding)\n",
    "# lat = (-10.855, -10.560)\n",
    "# lon = (35.130, 35.400)\n",
    "\n",
    "# Soybean Fields in Western Kenya (from Kizito)\n",
    "# lat = (-0.801180, -0.483689) # entire region\n",
    "# lon = (34.193792, 34.546329) # entire region\n",
    "\n",
    "# Ghana\n",
    "latitude = (5.5813, 5.6004)\n",
    "longitude = (-0.5398, -0.5203)\n",
    "\n",
    "# Time Period\n",
    "start_date, end_date = dt.datetime(2013,1,1), dt.datetime(2018,12,31)\n",
    "time_extents = (start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the selected area**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,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\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7fc481550588>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_map(longitude,latitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"load_data\">Load Data from the Data Cube and Obtain the Vegetation Proxy [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Vegetation Proxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change which line is commented out in order to switch vegetation proxy. NDVI is the recomended Vegetation Proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "veg_proxy = 'NDVI'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "once proxy is selected load data and mask out cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:   (time: 102, x: 64, y: 82)\n",
       "Coordinates:\n",
       "  * time      (time) datetime64[ns] 2013-04-20T10:17:29.521651 ... 2017-12-27T10:15:52.569447\n",
       "  * y         (y) float64 7.134e+05 7.133e+05 7.133e+05 ... 7.11e+05 7.109e+05\n",
       "  * x         (x) float64 -5.21e+04 -5.206e+04 ... -5.024e+04 -5.020e+04\n",
       "Data variables:\n",
       "    red       (time, y, x) float64 nan nan nan ... 1.092e+03 1.002e+03 1.011e+03\n",
       "    nir       (time, y, x) float64 nan nan nan ... 2.868e+03 2.917e+03 2.909e+03\n",
       "    pixel_qa  (time, y, x) float64 nan nan nan nan ... 322.0 322.0 322.0 322.0\n",
       "Attributes:\n",
       "    crs:      EPSG:6933"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measurements = []\n",
    "if veg_proxy == 'NDVI':\n",
    "    measurements = ['red', 'nir', 'pixel_qa']\n",
    "elif veg_proxy == 'EVI':\n",
    "    measurements = ['red', 'blue', 'nir', 'pixel_qa']\n",
    "\n",
    "\n",
    "landsat_dataset = dc.load(product = 'ls8_usgs_sr_scene',\n",
    "                          measurements = measurements,\n",
    "                          y = latitude,\n",
    "                          x = longitude,\n",
    "                          time = time_extents,\n",
    "                          output_crs='EPSG:6933',\n",
    "                          resolution=(-30,30))\n",
    "\n",
    "#load cloud mask and apply to dataset\n",
    "cloud_mask = landsat_qa_clean_mask(landsat_dataset, platform='LANDSAT_8')\n",
    "dataset = landsat_dataset.where(cloud_mask)\n",
    "\n",
    "#view masked dataset\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (latitude: 82, longitude: 64, time: 102)\n",
       "Coordinates:\n",
       "  * time       (time) datetime64[ns] 2013-04-20T10:17:29.521651 ... 2017-12-27T10:15:52.569447\n",
       "  * latitude   (latitude) float64 7.134e+05 7.133e+05 ... 7.11e+05 7.109e+05\n",
       "  * longitude  (longitude) float64 -5.21e+04 -5.206e+04 ... -5.020e+04\n",
       "Data variables:\n",
       "    red        (time, latitude, longitude) float64 nan nan ... 1.011e+03\n",
       "    nir        (time, latitude, longitude) float64 nan nan ... 2.909e+03\n",
       "    pixel_qa   (time, latitude, longitude) float64 nan nan nan ... 322.0 322.0\n",
       "Attributes:\n",
       "    crs:      EPSG:6933"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change Coordinate names to be compatible with modules used latter in this notebook\n",
    "dataset = dataset.rename(name_dict={'x':'longitude','y':'latitude'})\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (latitude: 82, longitude: 64, time: 102)\n",
       "Coordinates:\n",
       "  * time       (time) datetime64[ns] 2013-04-20T10:17:29.521651 ... 2017-12-27T10:15:52.569447\n",
       "  * latitude   (latitude) float64 7.134e+05 7.133e+05 ... 7.11e+05 7.109e+05\n",
       "  * longitude  (longitude) float64 -5.21e+04 -5.206e+04 ... -5.020e+04\n",
       "Data variables:\n",
       "    red        (time, latitude, longitude) float64 nan nan ... 1.011e+03\n",
       "    nir        (time, latitude, longitude) float64 nan nan ... 2.909e+03\n",
       "    pixel_qa   (time, latitude, longitude) float64 nan nan nan ... 322.0 322.0\n",
       "    NDVI       (time, latitude, longitude) float64 nan nan nan ... 0.4886 0.4842\n",
       "Attributes:\n",
       "    crs:      EPSG:6933"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate CHosen Vegitation Proxy\n",
    "if veg_proxy == 'NDVI':\n",
    "    dataset[veg_proxy] = NDVI(dataset)\n",
    "if veg_proxy == 'EVI':\n",
    "    dataset[veg_proxy] = EVI(dataset)\n",
    "    \n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"phenology_products\">Create Phenology Products[&#9652;](#top)</span>\n",
    "\n",
    "If no plots appear in the figures below, there is no data available for the region selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"phenology_plot_1\">Plot the Vegetation Index Over Time in a Box-and-Whisker Plot[&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:red\";><b>CHANGE INPUTS BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify whether to plot a curve fit of the vegetation index along time. Input can be either TRUE or FALSE\n",
    "plot_curve_fit = True\n",
    "assert isinstance(plot_curve_fit, bool), \"The variable 'plot_curve_fit' must be \"\\\n",
    "                                         \"either True or False.\"\n",
    "\n",
    "# Specify the target aggregation type of the curve fit. Input can be either 'mean' or 'median'.\n",
    "curve_fit_target = 'median'\n",
    "assert curve_fit_target in ['mean', 'median'], \"The variable 'curve_fit_target' must be either \"\\\n",
    "                                               \"'mean' or 'median'.\"\n",
    "\n",
    "# The maximum number of data points that appear along time in each plot.\n",
    "# If more than this number of data points need to be plotted, a grid of plots will be created.\n",
    "max_times_per_plot = 40 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:red\";><b>CHANGE INPUTS BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select the binning approach for the vegetation index. Set the 'bin_by' parameter.\n",
    "# None          = do not bin the data\n",
    "# 'week'        = bin the data by week with an extended time axis\n",
    "# 'month'       = bin the data by month with an extended time axis\n",
    "# 'weekofyear'  = bin the data by week and years using a single year time axis\n",
    "# 'monthofyear' = bin the data by month and years using a single year time axis\n",
    "\n",
    "# It is also possible to change some of the plotting features using the code below.\n",
    "\n",
    "bin_by = 'monthofyear'\n",
    "assert bin_by in [None, 'week', 'month', 'weekofyear', 'monthofyear'], \\\n",
    "    \"The variable 'bin_by' can only have one of these values: \"\\\n",
    "    \"[None, 'week', 'month', 'weekofyear', 'monthofyear']\"\n",
    "\n",
    "aggregated_by_str = None\n",
    "if bin_by is None:\n",
    "    plotting_data = dataset\n",
    "elif bin_by == 'week':\n",
    "    plotting_data = dataset.resample(time='1w').mean()\n",
    "    aggregated_by_str = 'Week'\n",
    "elif bin_by == 'month':\n",
    "    plotting_data = dataset.resample(time='1m').mean()\n",
    "    aggregated_by_str = 'Month'\n",
    "elif bin_by == 'weekofyear':\n",
    "    plotting_data = dataset.groupby('time.week').mean(dim=('time'))\n",
    "    aggregated_by_str = 'Week of Year'\n",
    "elif bin_by == 'monthofyear':\n",
    "    plotting_data = dataset.groupby('time.month').mean(dim=('time'))\n",
    "    aggregated_by_str = 'Month of Year'\n",
    "    \n",
    "params = dict(dataset=plotting_data, plot_descs={veg_proxy:{'none':[\n",
    "    {'box':{'boxprops':{'facecolor':'forestgreen'}}}]}})\n",
    "if plot_curve_fit:\n",
    "    params['plot_descs'][veg_proxy][curve_fit_target] = [{'gaussian_filter':{}}]\n",
    "    \n",
    "xarray_time_series_plot(**params, fig_params=dict(figsize=(12,8), dpi=150), \n",
    "                        max_times_per_plot=max_times_per_plot)\n",
    "plt.title('Box-and-Whisker Plot of {0} with a Curvefit of Median {0}'.format(veg_proxy))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"phenology_plot_2\">Plot the Vegetation Index Over Time for Each Year[&#9652;](#top)</span>\n",
    "Note that the curve fits here do not show where some times have no data (encoded as NaNs), as is shown in the box-and-whisker plot. Notably, the curve fits interpolate over times with missing data that are not the first or last time (e.g. January or December for monthly binned data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:red\";><b>CHANGE INPUTS BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_with_data = []\n",
    "plot_descs = {}\n",
    "daysofyear_per_year = {}\n",
    "plotting_data_years = {}\n",
    "time_dim_name = None\n",
    "for year in range(start_date.year, end_date.year+1):\n",
    "    year_data = dataset.sel(time=slice('{}-01-01'.format(year), '{}-12-31'.format(year)))[veg_proxy]\n",
    "    if len(year_data['time']) == 0: # There is nothing to plot for this year.\n",
    "        print(\"Year {} has no data, so will not be plotted.\".format(year))\n",
    "        continue\n",
    "    years_with_data.append(year)\n",
    "    \n",
    "    spec_ind_dayofyear = year_data.groupby('time.dayofyear').mean()\n",
    "    daysofyear_per_year[year] = spec_ind_dayofyear[~spec_ind_dayofyear.isnull()].dayofyear\n",
    "    \n",
    "# Select the binning approach for the vegetation index. Set the 'bin_by' parameter.\n",
    "# 'weekofyear'  = bin the data by week and years using a single year time axis\n",
    "# 'monthofyear' = bin the data by month and years using a single year time axis\n",
    "\n",
    "    bin_by = 'monthofyear'\n",
    "    \n",
    "    assert bin_by in ['weekofyear', 'monthofyear'], \\\n",
    "        \"The variable 'bin_by' can only have one of these values: \"\\\n",
    "        \"['weekofyear', 'monthofyear']\"\n",
    "    \n",
    "    aggregated_by_str = None\n",
    "    if bin_by == 'weekofyear':\n",
    "        plotting_data_year = year_data.groupby('time.week').mean(dim=('time'))\n",
    "        time_dim_name = 'week'\n",
    "    elif bin_by == 'monthofyear':\n",
    "        plotting_data_year = year_data.groupby('time.month').mean(dim=('time'))\n",
    "        time_dim_name = 'month'\n",
    "\n",
    "    plotting_data_years[year] = plotting_data_year\n",
    "    num_time_pts = len(plotting_data_year[time_dim_name])\n",
    "    \n",
    "    # Select the curve-fit type. \n",
    "    # See the documentation for `xarray_time_series_plot()` regarding the `plot_descs` parameter.\n",
    "    plot_descs[year] = {'mean':[{'gaussian_filter':{}}]}\n",
    "\n",
    "time_dim_name = 'week' if bin_by == 'weekofyear' else 'month' if bin_by == 'monthofyear' else 'time'\n",
    "\n",
    "num_times = 54 if bin_by == 'weekofyear' else 12\n",
    "time_coords_arr = np.arange(1, num_times+1) # In xarray, week and month indices start at 1.\n",
    "time_coords_da = xr.DataArray(time_coords_arr, coords={time_dim_name:time_coords_arr}, \n",
    "                              dims=[time_dim_name], name=time_dim_name)\n",
    "coords = dict(list(plotting_data_years.values())[0].coords)\n",
    "coords[time_dim_name] = time_coords_da \n",
    "plotting_data = xr.Dataset(plotting_data_years, coords=coords)\n",
    "params = dict(dataset=plotting_data, plot_descs=plot_descs)\n",
    "\n",
    "fig, curve_fit_plotting_data = \\\n",
    "    xarray_time_series_plot(**params, fig_params=dict(figsize=(8,4), dpi=150))\n",
    "plt.title('Line Plot of {0} for Each Year'.format(veg_proxy))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"export\">Export Curve Fits to a CSV File [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to a `pandas.DataFrame`.\n",
    "dataarrays = []\n",
    "for (year, _, _), dataarray in curve_fit_plotting_data.items():\n",
    "    dataarrays.append(dataarray.rename(year))\n",
    "curve_fit_df = xr.merge(dataarrays).to_dataframe()\n",
    "\n",
    "# Convert the month floats to day ints and average by day (scale to [0,1], multiply by 364, add 1).\n",
    "curve_fit_df.index.values[:] = (364/11) * (curve_fit_df.index.values - 1) + 1\n",
    "curve_fit_df.index = curve_fit_df.index.astype(int)\n",
    "curve_fit_df.index.name = 'day of year'\n",
    "curve_fit_df = curve_fit_df.groupby('day of year').mean()\n",
    "\n",
    "# Export the data to a CSV.\n",
    "csv_output_dir = 'output/CSVs/'\n",
    "if not os.path.exists(csv_output_dir):\n",
    "    os.makedirs(csv_output_dir)\n",
    "curve_fit_df.to_csv(csv_output_dir + 'vegetation_phenology_yearly_curve_fits_landsat.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"timesat\">Show [TIMESAT](http://web.nateko.lu.se/timesat/timesat.asp) Stats [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TIMESAT_stats(dataarray, time_dim='time'):\n",
    "    \"\"\"\n",
    "    For a 1D array of values for a vegetation index - for which higher values tend to \n",
    "    indicate more vegetation - determine several statistics:\n",
    "    1. Beginning of Season (BOS): The time index of the beginning of the growing season.\n",
    "        (The downward inflection point before the maximum vegetation index value)\n",
    "    2. End of Season (EOS): The time index of the end of the growing season.\n",
    "        (The upward inflection point after the maximum vegetation index value)\n",
    "    3. Middle of Season (MOS): The time index of the maximum vegetation index value.\n",
    "    4. Length of Season (EOS-BOS): The time length of the season (index difference).\n",
    "    5. Base Value (BASE): The minimum vegetation index value.\n",
    "    6. Max Value (MAX): The maximum vegetation index value (the value at MOS).\n",
    "    7. Amplitude (AMP): The difference between BASE and MAX.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataarray: xarray.DataArray\n",
    "        The 1D array of non-NaN values to determine the statistics for.\n",
    "    time_dim: string\n",
    "        The name of the time dimension in `dataarray`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    stats: dict\n",
    "        A dictionary mapping statistic names to values.\n",
    "    \"\"\"\n",
    "    assert time_dim in dataarray.dims, \"The parameter `time_dim` is \\\"{}\\\", \" \\\n",
    "        \"but that dimension does not exist in the data.\".format(time_dim)\n",
    "    stats = {}\n",
    "    data_np_arr = dataarray.values\n",
    "    time_np_arr = dataarray[time_dim].values\n",
    "    data_inds = np.arange(len(data_np_arr))\n",
    "    \n",
    "    # Obtain the first and second derivatives.\n",
    "    fst_deriv = np.gradient(data_np_arr, time_np_arr)\n",
    "    pos_fst_deriv = fst_deriv > 0\n",
    "    neg_fst_deriv = 0 > fst_deriv\n",
    "    snd_deriv = np.gradient(fst_deriv, time_np_arr)\n",
    "    pos_snd_deriv = snd_deriv > 0\n",
    "    neg_snd_deriv = 0 > snd_deriv\n",
    "    \n",
    "    # Determine MOS.\n",
    "    # MOS is the index of the highest value immediately preceding a transition\n",
    "    # of the first derivative from positive to negative.\n",
    "    pos_to_neg_fst_deriv = pos_fst_deriv.copy()\n",
    "    for i in range(len(pos_fst_deriv)):\n",
    "        if i == len(pos_fst_deriv) - 1: # last index\n",
    "            pos_to_neg_fst_deriv[i] = False\n",
    "        elif pos_fst_deriv[i] and not pos_fst_deriv[i+1]: # + to -\n",
    "            pos_to_neg_fst_deriv[i] = True\n",
    "        else: # everything else\n",
    "            pos_to_neg_fst_deriv[i] = False\n",
    "    idxmos_potential_inds = data_inds[pos_to_neg_fst_deriv]\n",
    "    idxmos_subset_ind = np.argmax(data_np_arr[pos_to_neg_fst_deriv])\n",
    "    idxmos = idxmos_potential_inds[idxmos_subset_ind]\n",
    "    stats['Middle of Season'] = idxmos\n",
    "    \n",
    "    data_inds_after_mos = np.roll(data_inds, len(data_inds)-idxmos-1)\n",
    "    \n",
    "    # Determine BOS.\n",
    "    # BOS is the first negative inflection point of the positive values \n",
    "    # of the first derivative starting after and ending at the MOS.\n",
    "    idxbos = data_inds_after_mos[np.argmax((pos_fst_deriv & neg_snd_deriv)[data_inds_after_mos])]\n",
    "    stats['Beginning of Season'] = idxbos\n",
    "    \n",
    "    # Determine EOS.\n",
    "    # EOS is the last positive inflection point of the negative values \n",
    "    # of the first derivative starting after and ending at the MOS.\n",
    "    idxeos = data_inds_after_mos[np.argmax((neg_fst_deriv & pos_snd_deriv)[data_inds_after_mos][::-1])]\n",
    "    stats['End of Season'] = idxeos\n",
    "    \n",
    "    # Determine EOS-BOS.\n",
    "    stats['Length of Season'] = idxeos - idxbos\n",
    "    # Determine BASE.\n",
    "    stats['Base Value'] = data_np_arr.min()\n",
    "    # Determine MAX.\n",
    "    stats['Max Value'] = data_np_arr.max()\n",
    "    # Determine AMP.\n",
    "    stats['Amplitude'] = stats['Max Value'] - stats['Base Value']\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Settings\n",
    "# The minimum number of weeks or months with data for a year to have its stats calculated.\n",
    "# The aggregation used to obtain the plotting data determines which of these is used.\n",
    "min_weeks_per_year = 40\n",
    "min_months_per_year = 9\n",
    "## End Settings\n",
    "\n",
    "for year, dataarray in plotting_data_years.items():\n",
    "    dataarray = dataarray.mean(['latitude', 'longitude'])\n",
    "    non_nan_mask = ~np.isnan(dataarray.values)\n",
    "    num_times = non_nan_mask.sum()\n",
    "    insufficient_data = False\n",
    "    if bin_by == 'weekofyear':\n",
    "        if num_times < min_weeks_per_year:\n",
    "            print(\"There are {} weeks with data for the year {}, but the \" \\\n",
    "                  \"minimum number of weeks is {}.\\n\".format(num_times, year, min_weeks_per_year))\n",
    "            continue\n",
    "    elif bin_by == 'monthofyear':\n",
    "        if num_times < min_months_per_year:\n",
    "            print(\"There are {} months with data for the year {}, but the \" \\\n",
    "                  \"minimum number of months is {}.\\n\".format(num_times, year, min_months_per_year))\n",
    "            continue\n",
    "    # Remove NaNs for `TIMESAT_stats()`.\n",
    "    dataarray = dataarray.sel({time_dim_name: dataarray[time_dim_name].values[non_nan_mask]})\n",
    "    stats = TIMESAT_stats(dataarray, time_dim=time_dim_name)\n",
    "    # Map indices to days of the year (can't use data from `daysofyear_per_year` directly\n",
    "    # because `xarray_time_series_plot()` can have more points for smooth curve fitting.\n",
    "    time_int_arr = dataarray[time_dim_name].values\n",
    "    orig_day_int_arr = daysofyear_per_year[year].values\n",
    "    day_int_arr = np.interp(time_int_arr, (time_int_arr.min(), time_int_arr.max()), \n",
    "                            (orig_day_int_arr.min(), orig_day_int_arr.max()))\n",
    "    # Convert \"times\" in the TIMESAT stats from indices to days (ints).\n",
    "    stats['Beginning of Season'] = int(round(day_int_arr[stats['Beginning of Season']]))\n",
    "    stats['Middle of Season'] = int(round(day_int_arr[stats['Middle of Season']]))\n",
    "    stats['End of Season'] = int(round(day_int_arr[stats['End of Season']]))\n",
    "    stats['Length of Season'] = np.abs(stats['End of Season'] - stats['Beginning of Season']) \n",
    "    \n",
    "    print(\"Year =\", year)\n",
    "    print(\"Beginning of Season (BOS) day =\", stats['Beginning of Season'])\n",
    "    print(\"End of Season (EOS) day =\", stats['End of Season'])\n",
    "    print(\"Middle of Season (MOS) day =\", stats['Middle of Season'])\n",
    "    print(\"Length of Season (abs(EOS-BOS)) in days =\", stats['Length of Season'])\n",
    "    print(\"Base Value (Min) =\", stats['Base Value'])\n",
    "    print(\"Max Value (Max) =\", stats['Max Value'])\n",
    "    print(\"Amplitude (Max-Min) =\", stats['Amplitude'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on modifications made moving from ARDC to DE Africa\n",
    "\n",
    "- Replace dc.load fuction with DE Africa dc.load fuction\n",
    "- changed code around loading data to just load and mask. Suggest replacing with DE Africa 'load masked usgs' \n",
    "- Move all module imports to start of notebook\n",
    "- Removed code to view extent of datacube replaced with mapviewer that can be used to visualise spatial extent of data\n",
    "- replaced save to geotiff fuction with datacube helper fuction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
