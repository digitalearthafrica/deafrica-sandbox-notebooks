{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General advice (delete this cell before submitting for review)\n",
    "\n",
    "> * When adding **Products used**, embed the hyperlink to that specific product on the DE Africa Explorer using the `[product_name](product url)` syntax.\n",
    "> * When writing in Markdown cells, start each sentence on a **new line**.\n",
    "This makes it easy to see changes through git commits.\n",
    "> * To faciliate the easy conversion of these notebooks into a docs help page, check the [known issues](https://github.com/GeoscienceAustralia/dea-docs/wiki/Known-issues) for formatting regarding the conversion of notebooks to DE Africa docs using Sphinx.\n",
    "Things to be aware of:\n",
    "    * Sphinx is highly sensitive to bulleted lists:\n",
    "        * Ensure that there is an empty line between any preceding text and the list\n",
    "        * Only use the `*` bullet (`-` is not recognised)\n",
    "        * Sublists must be indented by 4 spaces\n",
    "    * Two kinds of formatting cannot be used simultaneously:\n",
    "        * Hyperlinked code: \\[\\`code_format\\`](hyperlink) fails\n",
    "        * Bolded code: \\*\\*\\`code_format\\`\\*\\* fails\n",
    "    * Headers must appear in hierachical order (`#`, `##`, `###`, `####`) and there can only be one title (`#`).\n",
    "> * Use the [PEP8 standard](https://www.python.org/dev/peps/pep-0008/) for code. To make sure all code in the notebook is consistent, you can use the `jupyterlab_code_formatter` tool: select each code cell, then click `Edit` and then one of the `Apply X Formatter` options (`YAPF` or `Black` are recommended). This will reformat the code in the cell to a consistent style.\n",
    "> * In the final notebook cell, include a set of relevant **keywords** which are used to build the DE Africa User Guide's [keyword Index](https://digital-earth-africa.readthedocs.io/en/latest/genindex.html).\n",
    "    * Use the list of approved documentation keywords on the [wiki page](https://github.com/digitalearthafrica/deafrica-sandbox-notebooks/wiki/List-of-Documentation-Keywords).\n",
    "    * Avoid using keywords that link to specific modules in `deafrica_tools`.\n",
    "    * Use all lower-case (unless the tag is an acronym), separate words with spaces\n",
    "    * Ensure the keywords cell below is in `Raw` format, rather than `Markdown` or `Code`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral-temporal feature inspection tool\n",
    "\n",
    "* **Products used:** \n",
    "[ls8_sr](https://explorer.digitalearth.africa/ls8_sr), \n",
    "[s2_l2a](https://explorer.digitalearth.africa/s2_l2a),\n",
    "[s1_rtc](https://explorer.digitalearth.africa/s2_rtc),\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Keywords** :index:`data used; landsat 8`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "This notebook is an outcome of the ODC 2021 women sprint. \n",
    "\n",
    "Spectral-temporal features from time-series Earth observation data are often used to distinguish land cover types and monitor their evolution over time. They are particularly useful for understanding dynamic ecosystems such as wetlands.\n",
    "\n",
    "Many methods have been developed to derive spectral and temporal features from optical or radar remote sensing data. Their effectiveness vary for different environments.\n",
    "Therefore, we want to develop a tool that allows a scientist to quickly inspect well-known spectral indices and time series metrics for any location.\n",
    "\n",
    "\n",
    "Contributors:\n",
    "\n",
    "Fang Yuan, Bex Dunn, Meghan Halabisky, Kate Fickas, Allison Bailey, (add yourself here)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "We want to build a tool that is:\n",
    "\n",
    "* interactive\n",
    "* using popular indicies and metrics\n",
    "* easy to use for beginners wanting to learn more about remote sensing\n",
    "* able to use all DE Africa input time series data\n",
    "* expandable to include more spectral and temporal features.\n",
    "\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-do list\n",
    "\n",
    "**Completed:**\n",
    "* polygon selector off map [ x ]\n",
    "* sentinel 2 data [ x ]\n",
    "\n",
    "**Must have:**\n",
    "* polygon selector off map [ x ] \n",
    "* sentinel 2 data [ x ]\n",
    "* all tasselled cap indices\n",
    "* time series plot for each  \n",
    "* a new function that lets you do the things, or all the functionality in this notebook.\n",
    "\n",
    "* edit the loading data function to return multiple datasets\n",
    "* edit the loading data function to output the indexes loaded as string/list\n",
    "    \n",
    "**Would like to have:** _(links to where you can get code to do this)_\n",
    "* multiple datasets (add landsat data) [using load ard notebook](./Using_load_ard.ipynb)\n",
    "* multiple indices (for a list, see [bandindices.py](../Tools/deafrica_tools/bandindices.py) or the [band index notebook](Calculating_band_indices.ipynb))\n",
    "* sentinel 1 data [sentinel1 notebook](../Datasets/Sentinel_1.ipynb)\n",
    "* spectral plot for each\n",
    "* climate data [era 5 climate data notebook](../Datasets/Climate_Data_ERA5_AWS.ipynb )\n",
    "* soil moisture [soil moisture notebook](../Datasets/Soil_Moisture.ipynb) \n",
    "* evapotranspiration\n",
    "* phenology/metrics/cycles [Vegetation_phenology.ipynb](./Vegetation_phenology.ipynb)\n",
    "* click on plotted points to retrieve the imagery for that timestamp\n",
    "* trends\n",
    "* statistical significance tests\n",
    "        \n",
    "**Handy links**    \n",
    "* [ipywidgets documentation](https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20List.html) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "Import Python packages that are used for the analysis.\n",
    "\n",
    "Use standard import commands; some are shown below. \n",
    "Begin with any `iPython` magic commands, followed by standard Python packages, then any additional functionality you need from the `Scripts` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import datacube\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up a Dask cluster (disabled for now)\n",
    "\n",
    "Dask can be used to better manage memory use and conduct the analysis in parallel.\n",
    "\n",
    "For this notebook, we'll use dask to lazy load data over an area of interest before evaluating the results over selected polygons.\n",
    "\n",
    "For an introduction to using Dask with Digital Earth Africa, see the [Dask notebook](../Beginners_guide/08_parallel_processing_with_dask.ipynb).\n",
    "\n",
    ">**Note**: We recommend opening the Dask processing window to view the different computations that are being executed; to do this, see the *Dask dashboard in DE Africa* section of the [Dask notebook](../Beginners_guide/08_parallel_processing_with_dask.ipynb).\n",
    "\n",
    "To activate Dask, set up the local computing cluster using the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the default function is updated to return the client so loaded data can be kept in memory later. Any change to this code will be ported back to the Tools.\n",
    "\n",
    "import os\n",
    "import dask\n",
    "from datacube.utils.dask import start_local_dask\n",
    "from datacube.utils.rio import configure_s3_access\n",
    "\n",
    "def create_local_dask_cluster(\n",
    "    spare_mem=\"3Gb\", aws_unsigned=True, display_client=True, **kwargs\n",
    "):\n",
    "    # configure dashboard link to go over proxy\n",
    "    dask.config.set(\n",
    "        {\n",
    "            \"distributed.dashboard.link\": os.environ.get(\n",
    "                \"JUPYTERHUB_SERVICE_PREFIX\", \"/\"\n",
    "            )\n",
    "            + \"proxy/{port}/status\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # start up a local cluster\n",
    "    client = start_local_dask(mem_safety_margin=spare_mem, **kwargs)\n",
    "\n",
    "    ## Configure GDAL for s3 access\n",
    "    configure_s3_access(aws_unsigned=aws_unsigned, client=client)\n",
    "\n",
    "    # Show the dask cluster settings\n",
    "    if display_client:\n",
    "        display(client)\n",
    "    \n",
    "    return client\n",
    "\n",
    "# not using dask while testing\n",
    "# client = create_local_dask_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some functions to load our data and run our app\n",
    "Work in progress\n",
    "* We have taken the notebookapp_crophealth.py script from the [Scripts](../Scripts) folder and are editing it in the cell below that starts with the line `# notebookapp_spectraltemporal.py`\n",
    "* Once we have it changed to our liking, we can move the cell below into [it's own app/module](../Scripts/notebookapp_spectraltemporal.py)\n",
    "\n",
    "The `run_spectraltemporal_app()` is moved to a cell after data is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/env/lib/python3.6/site-packages/geopandas/_compat.py:88: UserWarning: The Shapely GEOS version (3.7.2-CAPI-1.11.0 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n"
     ]
    }
   ],
   "source": [
    "# notebookapp_spectraltemporal.py\n",
    "'''\n",
    "This file contains functions for loading and interacting with data in the\n",
    "spectral temporal widget notebook in the Frequently used code folder.\n",
    "\n",
    "Available functions:\n",
    "    load_spectraltemporal_data\n",
    "    run_spectraltemporal_app\n",
    "\n",
    "Last modified: June 2021\n",
    "'''\n",
    "\n",
    "# Load modules\n",
    "from ipyleaflet import (\n",
    "    Map,\n",
    "    GeoJSON,\n",
    "    DrawControl,\n",
    "    basemaps\n",
    ")\n",
    "import datetime as dt\n",
    "import datacube\n",
    "from osgeo import ogr\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from rasterio.features import geometry_mask\n",
    "import xarray as xr\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "import ipywidgets as widgets\n",
    "import json\n",
    "import geopandas as gpd\n",
    "from io import BytesIO\n",
    "\n",
    "# Load utility functions\n",
    "from deafrica_tools.datahandling import load_ard\n",
    "from deafrica_tools.load_era5 import load_era5\n",
    "from deafrica_tools.spatial import xr_rasterize\n",
    "from deafrica_tools.bandindices import calculate_indices\n",
    "\n",
    "\n",
    "def load_spectraltemporal_data(lat, lon, buffer, time):\n",
    "    \"\"\"\n",
    "    Loads Sentinel-2 analysis-ready data (ARD) product for the case-study area over the last two years.\n",
    "    Calculates indices as required using the calculate_indices script.\n",
    "    Last modified: June 2021\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lat: float\n",
    "        The central latitude to analyse\n",
    "    lon: float\n",
    "        The central longitude to analyse\n",
    "    buffer:\n",
    "         The number of square degrees to load around the central latitude and longitude. \n",
    "         For reasonable loading times, set this as `0.1` or lower.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    ds: xarray.Dataset \n",
    "        data set containing combined, masked data\n",
    "        Masked values are set to 'nan'\n",
    "    \"\"\"\n",
    "    \n",
    "    # Suppress warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    # Initialise the data cube. 'app' argument is used to identify this app\n",
    "    dc = datacube.Datacube(app='spectraltemporal_app')\n",
    "    \n",
    "    # Define area to load\n",
    "    latitude = (lat - buffer, lat + buffer)\n",
    "    longitude = (lon - buffer, lon + buffer)\n",
    "\n",
    "    # Construct the data cube query for s2\n",
    "    products = [\"s2_l2a\"]\n",
    "    \n",
    "    query = {\n",
    "        'x': longitude,\n",
    "        'y': latitude,\n",
    "        'time': time,\n",
    "        'measurements': [\n",
    "            'red',\n",
    "            'green',\n",
    "            'blue',\n",
    "            'nir',\n",
    "            'swir_1',        \n",
    "            'swir_2'\n",
    "        ],\n",
    "        'output_crs': 'EPSG:6933',\n",
    "        'resolution': (-20, 20)\n",
    "    }\n",
    "\n",
    "    # Load the data and mask out bad quality pixels\n",
    "    s2 = load_ard(dc, products=products, min_gooddata=0.5, **query)\n",
    "\n",
    "    # Calculate the desired indices\n",
    "    # e.g. ds = calculate_indices(ds, index='NDVI', collection='s2')\n",
    "\n",
    "    s2 = calculate_indices(s2, index= ['TCW', 'TCB', 'TCG'], collection= 's2') #NOTE - this is super dodgy as these are not the coefficents for S2...\n",
    "    \n",
    "    # construct data query for s1\n",
    "    products = [\"s1_rtc\"]\n",
    "    \n",
    "    # for now, reproject to the same grid as s2, can also use native lat/lon grid\n",
    "    query = {\n",
    "        'x': longitude,\n",
    "        'y': latitude,\n",
    "        'time': time,\n",
    "        'measurements': ['vv', 'vh'],\n",
    "        'output_crs': 'EPSG:6933',\n",
    "        'resolution': (-20, 20)\n",
    "    }\n",
    "\n",
    "    # Load the data and mask out bad quality pixels\n",
    "    s1 = load_ard(dc, products=products, min_gooddata=0.5, **query)\n",
    "    \n",
    "    # Caculate radar vegetation index\n",
    "    s1['rvi'] = 4*s1.vh/(s1.vv+s1.vh)\n",
    "\n",
    "    # precipitation data\n",
    "    precip = load_era5('precipitation_amount_1hour_Accumulation', latitude, longitude, time, reduce_func=np.sum, resample='1D').compute()\n",
    "    # rename the vararible to something easier to use\n",
    "    precip = precip.rename({'precipitation_amount_1hour_Accumulation':'precip'})\n",
    "    \n",
    "    # Return the data\n",
    "    return(s2, s1, precip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube\n",
    "\n",
    "Connect to the datacube so we can access DE Africa data.\n",
    "The `app` parameter is a unique name for the analysis which is based on the notebook file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/env/lib/python3.6/site-packages/datacube/drivers/postgres/_connections.py:87: SADeprecationWarning: Calling URL() directly is deprecated and will be disabled in a future release.  The public constructor for URL is now the URL.create() method.\n",
      "  username=username, password=password,\n"
     ]
    }
   ],
   "source": [
    "dc = datacube.Datacube(app='Spectral_temporal_widget')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define area and time period of interest\n",
    "\n",
    "The area of interest (AOI) is used to pre-(lazy)-load the data and define the area to show in the interactive widget.\n",
    "\n",
    "We use three parameters to define the AOI:\n",
    "\n",
    "* `lat`: The central latitude to analyse (e.g. `-19.3`).\n",
    "* `lon`: The central longitude to analyse (e.g. `23.3`).\n",
    "* `buffer`: The number of square degrees to load around the central latitude and longitude.\n",
    "\n",
    "Keep the AOI small for testing.\n",
    "When the tool is working and dask is implemented, it will be easier to work with larger AOI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the area of interest for the analysis\n",
    "lat = -19.3\n",
    "lon = 23.3\n",
    "buffer = 0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allow selection of time period. Use two years for now.\n",
    "\n",
    "Noting ERA5 climate data is only updated monthly, so including recent dates might fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = '2019', '2020'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "The `load_spectraltemporal_data()` command performs several key steps:\n",
    "\n",
    "* identify all available Sentinel-2, Sentinel-1 and climiate data in the case-study area over the two years\n",
    "* remove any bad quality pixels\n",
    "* keep images where more than half of the image contains good quality pixels\n",
    "* calculate indices\n",
    "* return the collated data for analysis\n",
    "\n",
    "The function returns cleaned and collated `dataset` objects.\n",
    "As the command runs, feedback will be provided below the cell, including information on the number of cleaned images loaded from each sensor.\n",
    "\n",
    "The function takes four arguments: `lat`, `lon`, `buffer` and `time`.\n",
    "These determine the area of interest and time period of interest that the function loads, and can be changed in the previous cell.\n",
    "\n",
    "**Please be patient**.\n",
    "The load is complete when the cell status goes from `[*]` to `[number]`.\n",
    "\n",
    "**Once the widget UI is finalized. We should use dask to not load all data upfront. This will avoid unnecessary data loading and make this tool faster.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pixel quality parameters for Sentinel 2\n",
      "Finding datasets\n",
      "    s2_l2a\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 113 out of 146 time steps with at least 50.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Loading 113 time steps\n",
      "Using pixel quality parameters for Sentinel 1\n",
      "Finding datasets\n",
      "    s1_rtc\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 60 out of 60 time steps with at least 50.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Loading 60 time steps\n"
     ]
    }
   ],
   "source": [
    "# load the data based off our set parameters\n",
    "datasets = load_spectraltemporal_data(lat, lon, buffer, time) ###FIXME update this function to take a string index identifier or a list of indices as an input variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<xarray.Dataset>\n",
       " Dimensions:      (time: 113, x: 49, y: 61)\n",
       " Coordinates:\n",
       "   * time         (time) datetime64[ns] 2019-01-06T08:45:42 ... 2020-12-26T08:...\n",
       "   * y            (y) float64 -2.416e+06 -2.416e+06 ... -2.418e+06 -2.418e+06\n",
       "   * x            (x) float64 2.248e+06 2.248e+06 ... 2.249e+06 2.249e+06\n",
       "     spatial_ref  int32 6933\n",
       " Data variables:\n",
       "     red          (time, y, x) float32 428.0 448.0 408.0 ... 791.0 1150.0 1366.0\n",
       "     green        (time, y, x) float32 452.0 479.0 432.0 ... 1538.0 1574.0 1898.0\n",
       "     blue         (time, y, x) float32 396.0 392.0 397.0 ... 1556.0 1522.0 2328.0\n",
       "     nir          (time, y, x) float32 1146.0 1170.0 1078.0 ... 3152.0 3364.0\n",
       "     swir_1       (time, y, x) float32 1774.0 1754.0 1615.0 ... 2749.0 2962.0\n",
       "     swir_2       (time, y, x) float32 1351.0 1338.0 1214.0 ... 2652.0 2843.0\n",
       "     TCW          (time, y, x) float32 -0.1613449 -0.15765351 ... -0.23358533\n",
       "     TCB          (time, y, x) float32 0.14062525 0.14382343 ... 0.42212355\n",
       "     TCG          (time, y, x) float32 0.031214183 0.03162435 ... 0.067711696\n",
       " Attributes:\n",
       "     crs:           EPSG:6933\n",
       "     grid_mapping:  spatial_ref, <xarray.Dataset>\n",
       " Dimensions:      (time: 60, x: 49, y: 61)\n",
       " Coordinates:\n",
       "   * time         (time) datetime64[ns] 2019-01-07T16:56:24.971588 ... 2020-12...\n",
       "   * y            (y) float64 -2.416e+06 -2.416e+06 ... -2.418e+06 -2.418e+06\n",
       "   * x            (x) float64 2.248e+06 2.248e+06 ... 2.249e+06 2.249e+06\n",
       "     spatial_ref  int32 6933\n",
       " Data variables:\n",
       "     vv           (time, y, x) float32 0.15091656 0.09345196 ... 0.13292688\n",
       "     vh           (time, y, x) float32 0.021437572 0.03129838 ... 0.07414222\n",
       "     rvi          (time, y, x) float32 0.49752384 1.0035526 ... 1.4322218\n",
       " Attributes:\n",
       "     crs:           EPSG:6933\n",
       "     grid_mapping:  spatial_ref, <xarray.Dataset>\n",
       " Dimensions:      (lat: 1, lon: 1, time: 731)\n",
       " Coordinates:\n",
       "   * time         (time) datetime64[ns] 2019-01-01 2019-01-02 ... 2020-12-31\n",
       "   * lat          (lat) float32 -19.25\n",
       "   * lon          (lon) float32 23.25\n",
       "     spatial_ref  int32 4326\n",
       " Data variables:\n",
       "     precip       (time, lat, lon) float32 0.010131836 0.030700684 ... 0.0\n",
       " Attributes:\n",
       "     institution:   ECMWF\n",
       "     source:        Reanalysis\n",
       "     title:         ERA5 forecasts\n",
       "     grid_mapping:  spatial_ref)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results are a list of three datasets\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the spectraltemporal app\n",
    "The `run_spectraltemporal_app()` command launches an interactive map.\n",
    "Drawing polygons within the red boundary (which represents the area covered by the loaded data) will result in plots of the average NDVI in that area.\n",
    "Draw polygons by clicking the &#11039; symbol in the app.\n",
    "\n",
    "The function works by taking the loaded data `dataset` as an argument, as well as the `lat`, `lon`, and `buffer` parameters used to define the spatial extent.\n",
    "\n",
    "> **Note:** data points will only appear for images where more than 50% of the pixels were classified as good quality. This may cause trend lines on the average NDVI plot to appear disconnected. Available data points will be marked with the `*` symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moved here to be close to the widget cell\n",
    "# now that the data is loaded, we can just tweak this function until the widget works as expected.\n",
    "\n",
    "# !!! Be aware that this function is very hard to debug because it doesn't display error messages....\n",
    "\n",
    "def run_spectraltemporal_app(s2, s1, era5, lat, lon, buffer):\n",
    "    \"\"\"\n",
    "    Plots an interactive map of the case-study area and allows\n",
    "    the user to draw polygons. This returns a plot of the average NDVI value\n",
    "    in the polygon area.\n",
    "    Last modified: June 2021\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ds: xarray.Dataset \n",
    "        data set containing combined, masked data\n",
    "        Masked values are set to 'nan'\n",
    "    lat: float\n",
    "        The central latitude corresponding to the area of loaded ds\n",
    "    lon: float\n",
    "        The central longitude corresponding to the area of loaded ds\n",
    "    buffer:\n",
    "         The number of square degrees to load around the central latitude and longitude. \n",
    "         For reasonable loading times, set this as `0.1` or lower.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Suppress warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    # Update plotting functionality through rcParams\n",
    "    mpl.rcParams.update({'figure.autolayout': True})\n",
    "    \n",
    "    # Define polygon bounds   \n",
    "    latitude = (lat - buffer, lat + buffer)\n",
    "    longitude = (lon - buffer, lon + buffer)\n",
    "\n",
    "    # Define the bounding box that will be overlayed on the interactive map\n",
    "    # The bounds are hard-coded to match those from the loaded data\n",
    "    geom_obj = {\n",
    "        \"type\": \"Feature\",\n",
    "        \"properties\": {\n",
    "            \"style\": {\n",
    "                \"stroke\": True,\n",
    "                \"color\": 'red',\n",
    "                \"weight\": 4,\n",
    "                \"opacity\": 0.8,\n",
    "                \"fill\": True,\n",
    "                \"fillColor\": False,\n",
    "                \"fillOpacity\": 0,\n",
    "                \"showArea\": True,\n",
    "                \"clickable\": True\n",
    "            }\n",
    "        },\n",
    "        \"geometry\": {\n",
    "            \"type\": \"Polygon\",\n",
    "            \"coordinates\": [\n",
    "                [\n",
    "                    [\n",
    "                        longitude[0],\n",
    "                        latitude[0]\n",
    "                    ],\n",
    "                    [\n",
    "                        longitude[1],\n",
    "                        latitude[0]\n",
    "                    ],\n",
    "                    [\n",
    "                        longitude[1],\n",
    "                        latitude[1]\n",
    "                    ],\n",
    "                    [\n",
    "                        longitude[0],\n",
    "                        latitude[1]\n",
    "                    ],\n",
    "                    [\n",
    "                        longitude[0],\n",
    "                        latitude[0]\n",
    "                    ]\n",
    "                ]\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Create a map geometry from the geom_obj dictionary\n",
    "    # center specifies where the background map view should focus on\n",
    "    # zoom specifies how zoomed in the background map should be\n",
    "    loadeddata_geometry = ogr.CreateGeometryFromJson(str(geom_obj['geometry']))\n",
    "    loadeddata_center = [\n",
    "        loadeddata_geometry.Centroid().GetY(),\n",
    "        loadeddata_geometry.Centroid().GetX()\n",
    "    ]\n",
    "    loadeddata_zoom = 16\n",
    "\n",
    "    # define the study area map\n",
    "    studyarea_map = Map(\n",
    "        center=loadeddata_center,\n",
    "        zoom=loadeddata_zoom,\n",
    "        basemap=basemaps.Esri.WorldImagery\n",
    "    )\n",
    "\n",
    "    # define the drawing controls\n",
    "    studyarea_drawctrl = DrawControl(\n",
    "        polygon={\"shapeOptions\": {\"fillOpacity\": 0}},\n",
    "        marker={},\n",
    "        circle={},\n",
    "        circlemarker={},\n",
    "        polyline={},\n",
    "    )\n",
    "\n",
    "    # add drawing controls and data bound geometry to the map\n",
    "    studyarea_map.add_control(studyarea_drawctrl)\n",
    "    studyarea_map.add_layer(GeoJSON(data=geom_obj))\n",
    "\n",
    "    # Index to count drawn polygons\n",
    "    polygon_number = 0\n",
    "\n",
    "    # Define widgets to interact with\n",
    "    instruction = widgets.Output(layout={'border': '1px solid black'})\n",
    "    with instruction:\n",
    "        print(\"Draw a polygon within the red box to view time series plots\")  #!!!!!!!!!!!!! Edit to give more instructions\n",
    "\n",
    "    info = widgets.Output(layout={'border': '1px solid black'})\n",
    "    with info:\n",
    "        print(\"Plot status:\")\n",
    "\n",
    "    fig_display = widgets.Output(layout=widgets.Layout(\n",
    "        width=\"50%\",  # proportion of horizontal space taken by plot\n",
    "    ))\n",
    "\n",
    "    #!!!!!!!!!!!Edit this section to set up multiple plots.\n",
    "    # number of plots needs to match the variables to be displayed.\n",
    "    # if more plots are needed, the layout can be redesigned\n",
    "    with fig_display:\n",
    "        plt.ioff()\n",
    "        fig, ax = plt.subplots(5, 1, figsize=(8, 12), sharex=True)\n",
    "        # use automatically generated limits?\n",
    "        #ax.set_ylim([0, 1]) - these limits won't work for the tasseled cap indices. need to set graph limits as a #FIXME\n",
    "        #ax[0].set_ylim([-1,1]) #- try this. I think this is using a \"normalised\" tci formula\n",
    "\n",
    "    colour_list = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "  \n",
    "    # Function to execute each time something is drawn on the map\n",
    "    def handle_draw(self, action, geo_json):\n",
    "        nonlocal polygon_number\n",
    "\n",
    "        # Execute behaviour based on what the user draws\n",
    "        if geo_json['geometry']['type'] == 'Polygon':\n",
    "\n",
    "            info.clear_output(wait=True)  # wait=True reduces flicker effect\n",
    "            \n",
    "            # Save geojson polygon to io temporary file to be rasterized later\n",
    "            jsonData = json.dumps(geo_json)\n",
    "            binaryData = jsonData.encode()\n",
    "            io = BytesIO(binaryData)\n",
    "            io.seek(0)\n",
    "            \n",
    "            # Read the polygon as a geopandas dataframe\n",
    "            gdf = gpd.read_file(io)\n",
    "            gdf.crs = \"EPSG:4326\"\n",
    "                \n",
    "            colour = colour_list[polygon_number % len(colour_list)]\n",
    "\n",
    "            # Add a layer to the map to make the most recently drawn polygon\n",
    "            # the same colour as the line on the plot\n",
    "            studyarea_map.add_layer(\n",
    "                GeoJSON(\n",
    "                    data=geo_json,\n",
    "                    style={\n",
    "                        'color': colour,\n",
    "                        'opacity': 1,\n",
    "                        'weight': 4.5,\n",
    "                        'fillOpacity': 0.0\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "\n",
    "            ax_idx = 0\n",
    "            \n",
    "            # Section for S2\n",
    "            # ===================\n",
    "            # Convert the drawn geometry to pixel coordinates to be used as a mask\n",
    "            xr_poly = xr_rasterize(gdf, s2)\n",
    "            \n",
    "            for var in ['TCW', 'TCG', 'TCB']:\n",
    "                # Construct a mask to only select pixels within the drawn polygon\n",
    "                masked_ds_mean = s2[var].where(xr_poly).mean(dim=['x', 'y'], skipna=True)\n",
    "        \n",
    "                # add new data to the plot\n",
    "                xr.plot.plot(\n",
    "                    masked_ds_mean,\n",
    "                    marker='*',\n",
    "                    color=colour,\n",
    "                    ax=ax[ax_idx]\n",
    "                )\n",
    "\n",
    "                # reset titles back to custom\n",
    "                ax[ax_idx].set_title(var) #FIXME set index/indices as a variable\n",
    "                ax[ax_idx].set_xlabel(\"\")\n",
    "                ax[ax_idx].set_ylabel(\"index\")\n",
    "                ax_idx +=1\n",
    "                \n",
    "            # section for S1\n",
    "            # ==========================\n",
    "            # Convert the drawn geometry to pixel coordinates to be used as a mask\n",
    "            s1_mask = xr_rasterize(gdf, s1)\n",
    "            \n",
    "            for var in ['rvi']:\n",
    "                # Construct a mask to only select pixels within the drawn polygon\n",
    "                masked_s1_mean = s1[var].where(s1_mask).mean(dim=['x', 'y'], skipna=True)\n",
    "        \n",
    "                # add new data to the plot\n",
    "                xr.plot.plot(\n",
    "                    masked_s1_mean,\n",
    "                    marker='*',\n",
    "                    color=colour,\n",
    "                    ax=ax[ax_idx]\n",
    "                )\n",
    "\n",
    "                # reset titles back to custom\n",
    "                ax[ax_idx].set_title(var) #FIXME set index/indices as a variable\n",
    "                ax[ax_idx].set_xlabel(\"\")\n",
    "                ax[ax_idx].set_ylabel(\"index\")\n",
    "                ax_idx +=1\n",
    "\n",
    "            # section for climate\n",
    "            # ==========================\n",
    "            # Convert the drawn geometry to pixel coordinates to be used as a mask\n",
    "            # masking is disabled because ERA5 has low resolution\n",
    "            # for the test AOI, ERA5 has one grid cell, rasterize doesn't work\n",
    "            # era5_mask = xr_rasterize(gdf, era5)\n",
    "            \n",
    "            for var in ['precip']:\n",
    "                # Construct a mask to only select pixels within the drawn polygon\n",
    "                masked_era5_mean = era5[var].mean(dim=['lat', 'lon'], skipna=True)\n",
    "\n",
    "                # add new data to the plot\n",
    "                xr.plot.plot(\n",
    "                    masked_era5_mean,\n",
    "                    marker='*',\n",
    "                    color=colour,\n",
    "                    ax=ax[ax_idx]\n",
    "                )\n",
    "\n",
    "                # reset titles back to custom\n",
    "                ax[ax_idx].set_title(var) #FIXME set index/indices as a variable\n",
    "                ax[ax_idx].set_ylabel(\"index\")\n",
    "                ax_idx +=1\n",
    "\n",
    "            ax[-1].set_xlabel(\"Date\")\n",
    "\n",
    "                       \n",
    "            # refresh display\n",
    "            fig_display.clear_output(wait=True)  # wait=True reduces flicker effect\n",
    "            with fig_display:\n",
    "                display(fig)\n",
    "                \n",
    "            with info:\n",
    "                print(\"Plot status: polygon sucessfully added to plot.\")\n",
    "\n",
    "            # Iterate the polygon number before drawing another polygon\n",
    "            polygon_number = polygon_number + 1\n",
    "\n",
    "        else:\n",
    "            info.clear_output(wait=True)\n",
    "            with info:\n",
    "                print(\"Plot status: this drawing tool is not currently \"\n",
    "                      \"supported. Please use the polygon tool.\")\n",
    "\n",
    "    # call to say activate handle_draw function on draw\n",
    "    studyarea_drawctrl.on_draw(handle_draw)\n",
    "\n",
    "    with fig_display:\n",
    "        # TODO: update with user friendly something\n",
    "        display(widgets.HTML(\"\"))\n",
    "\n",
    "    # Construct UI:\n",
    "    #  +-----------------------+\n",
    "    #  | instruction           |\n",
    "    #  +-----------+-----------+\n",
    "    #  |  map      |  plot     |\n",
    "    #  |           |           |\n",
    "    #  +-----------+-----------+\n",
    "    #  | info                  |\n",
    "    #  +-----------------------+\n",
    "    ui = widgets.VBox([instruction,\n",
    "                       widgets.HBox([studyarea_map, fig_display]), #add more boxes to the layout to add more plots\n",
    "                       info])\n",
    "    display(ui)\n",
    "    \n",
    "\n",
    "# Alternative UI design?\n",
    "\n",
    "    # Construct UI:\n",
    "    #  +-----------------------+\n",
    "    #  | instruction           |\n",
    "    #  +-----------+-----------+\n",
    "    #  |  map      / info      |\n",
    "    #  |                       |\n",
    "    #  +-----------+-----------+\n",
    "    #  /  plot grid            /\n",
    "    #  /                       /\n",
    "    #  +-----------+-----------+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03de6d0dadab416fa95df99c84468387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Output(layout=Layout(border='1px solid black')), HBox(children=(Map(center=[-19.299999999999997â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run the app\n",
    "run_spectraltemporal_app(datasets[0], datasets[1], datasets[2], lat, lon, buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More wetland stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use code comments for low-level documentation of code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Africa data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/digitalearthafrica/deafrica-sandbox-notebooks).\n",
    "\n",
    "**Compatible datacube version:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datacube.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Last Tested:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "datetime.today().strftime('%Y-%m-%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
