{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image segmentation <img align=\"right\" src=\"../Supplementary_data/DE_Africa_Logo_Stacked_RGB_small.jpg\">\n",
    "\n",
    "\n",
    "* **Products used:** \n",
    "s2a_msil2a, s2b_msil2a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "In the last two decades, as the spatial resolution of satellite images has increased, remote sensing has begun to shift from a focus on pixel-based analysis towards Geographic Object-Based Image Analysis (GEOBIA), which aims to group pixels together into meaningful image-objects. \n",
    "There are two advantages to a GEOBIA worklow; one, we can reduce the 'salt and pepper' effect typical of classifying pixels; and two, we can increase the computational efficiency of our workflow by grouping pixels into fewer, larger, but meaningful objects. \n",
    "A review of the emerging trends in GEOBIA can be found in [Chen et al. (2017)](https://www.tandfonline.com/doi/abs/10.1080/15481603.2018.1426092)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "This notebook demonstrates two methods for conducting `image segmentation`, which is a common image analysis technique used to transform a digital satellite image into objects. \n",
    "In brief, [image segmentation](https://en.wikipedia.org/wiki/Image_segmentation) aims to partition an image into segments, where each segment consists of a group of pixels with similar characteristics. \n",
    "The algorithm used to perform image segmentation here is:\n",
    "\n",
    "1. [Quickshift](https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.quickshift), implemented through the python package `scikit-image`\n",
    "\n",
    "\n",
    "**Note:** Image segmentation at very large scales can be both time and memory intensive, and the examples shown here will become prohibitively time consuming at scale. \n",
    "The notebook [Tiled, Parallel Image Segmentation](https://github.com/GeoscienceAustralia/dea-notebooks/blob/chad/segmentation/parallel_segmentation.ipynb) builds upon the image segmentation algorithm developed by [Shepherd et al. (2019)](https://www.mdpi.com/2072-4292/11/6/658) to run image segmentation across multiple cpus.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import datacube\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from osgeo import gdal\n",
    "from datacube.helpers import write_geotiff\n",
    "from skimage.segmentation import quickshift, slic\n",
    "\n",
    "sys.path.append('../Scripts')\n",
    "from deafrica_datahandling import array_to_geotiff\n",
    "from deafrica_datahandling import load_ard, mostcommon_crs\n",
    "from deafrica_plotting import rgb, display_map\n",
    "from deafrica_bandindices import calculate_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app='Image_segmentation')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat, lon =  6.5, 1.4\n",
    "buffer = 0.075\n",
    "\n",
    "x = (lon - buffer, lon + buffer)\n",
    "y =  (lat + buffer, lat - buffer)\n",
    "\n",
    "# Create a reusable query\n",
    "query = {\n",
    "    'x': x,\n",
    "    'y': y,\n",
    "    'time': ('2018-01', '2018-06'),\n",
    "    'resolution': (-30, 30)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the selected location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_map(x=x, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sentinel 2 data from the datacube\n",
    "\n",
    "Here we are loading in a timeseries of `Sentinel 2` satellite images through the datacube API using the [load_ard](https://github.com/GeoscienceAustralia/dea-notebooks/blob/develop/Frequently_used_code/Using_load_ard.ipynb) function. This will provide us with some data to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_crs = mostcommon_crs(dc=dc, product='s2a_msil2a', query=query)\n",
    "\n",
    "# Load available data from all three Landsat satellites\n",
    "ds = load_ard(dc=dc, \n",
    "              products=['s2a_msil2a', 's2b_msil2a'],\n",
    "                group_by='solar_day', output_crs=output_crs, \n",
    "              **query)\n",
    "\n",
    "# Print output data\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine observations into a noise-free statistical summary image\n",
    "Individual remote sensing images can be affected by noisy and incomplete data (e.g. due to clouds). To produce cleaner images that we can feed into the image segmentation algorithm, we can create summary images, or composites, that combine multiple images into one image to reveal the 'typical' appearance of the landscape for a certain time period.  In the code below, we take the noisy, incomplete satellite images we just loaded and calculate the mean Normalised Difference Vegetation Index (NDVI).  The mean NDVI will be our input into the segmentation algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate mean NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we calculate NDVI on each image in the timeseries\n",
    "ndvi = calculate_indices(ds, index='NDVI', collection='s2')\n",
    "\n",
    "# For each pixel, calculate the mean NDVI throughout the whole timeseries\n",
    "ndvi = ndvi.mean(dim='time', keep_attrs=True)\n",
    "\n",
    "# Plot the results to inspect\n",
    "ndvi.NDVI.plot(vmin=0.1, vmax=1.0, cmap='gist_earth_r', figsize=(10, 10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickshift Segmentation\n",
    "\n",
    "Using the function [quickshift](https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.quickshift) from the python package `scikit-image`, we will conduct an image segmentation on the mean NDVI array.  We then calculate a zonal mean across each segment using the input dataset. Our last step is to export our results as a GeoTIFF.\n",
    "\n",
    "Follow the quickshift hyperlink above to see the input parameters to the algorithm, and the following [link](https://scikit-image.org/docs/dev/auto_examples/segmentation/plot_segmentations.html) for an explanation of quickshift and other segmentation algorithms in `scikit-image`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our mean NDVI xarray into a numpy array, we need\n",
    "# to be explicit about the datatype to satisfy quickshift\n",
    "input_array = ndvi.NDVI.values.astype(np.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the segments\n",
    "segments = quickshift(input_array,\n",
    "                      kernel_size=5,\n",
    "                      convert2lab=False,\n",
    "                      max_dist=10,\n",
    "                      ratio=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the zonal mean NDVI across the segments\n",
    "segments_zonal_mean_qs = scipy.ndimage.mean(input=input_array,\n",
    "                                            labels=segments,\n",
    "                                            index=segments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to see result\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(segments_zonal_mean_qs, cmap='gist_earth_r', vmin=0.1, vmax=1.0)\n",
    "plt.colorbar(shrink=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export result to GeoTIFF\n",
    "See this [notebook](../Frequently_used_code/Exporting_GeoTIFFs.ipynb) for more info on writing GeoTIFFs to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = ds.geobox.transform.to_gdal()\n",
    "projection = ds.geobox.crs.wkt\n",
    "\n",
    "# Export the array\n",
    "array_to_geotiff('segmented_meanNDVI_QS.tif',\n",
    "                  segments_zonal_mean_qs,\n",
    "                  geo_transform=transform,\n",
    "                  projection=projection,\n",
    "                  nodata_val=np.nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Australia data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/GeoscienceAustralia/dea-notebooks).\n",
    "\n",
    "**Last modified:** December 2019\n",
    "\n",
    "**Compatible datacube version:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datacube.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags\n",
    "At some stage you might be able to browse all available tags on the DE Africa User Guide's [Tags Index](https://docs.dea.ga.gov.au/genindex.html)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**: :index:`NCI compatible`, :index:`sentinel 2`, :index:`deafrica_datahandling`, :index:`deafrica_plotting`, :index:`deafrica_bandindices`, :index:`array_to_geotiff`, :index:`load_ard`, :index:`rgb`, :index:`calculate_indices`, :index:`image segmentation`, :index:`image compositing`,  :index:`scikit-image`, :index:`GEOBIA`, :index:`quickshift`, :index:`NDVI`, :index:`GeoTIFF`, :index:`exporting data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
