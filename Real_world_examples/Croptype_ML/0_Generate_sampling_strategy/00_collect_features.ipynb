{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6167488-2a58-4b41-87b1-7d3357ccf035",
   "metadata": {},
   "source": [
    "**AIM:** \n",
    "\n",
    "run kmeans fit on all of central\n",
    "\n",
    "**STEPS:**\n",
    "\n",
    "* load data for all of central region\n",
    "* mask to central region\n",
    "* mask to crop mask\n",
    "* flatten and remove nans\n",
    "* fit kmeans to all central crop data\n",
    "* look at results in a number of small areas using 5, 10, 15 crop classes\n",
    "* Use model to predict everywhere. Use xr_predict to deal with areas that aren't needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7515187-ae7e-497b-8dad-5a4dcc9c6cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import datacube\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rioxarray\n",
    "import xarray as xr\n",
    "import os\n",
    "from datacube.utils import geometry\n",
    "from deafrica_tools.bandindices import calculate_indices\n",
    "from deafrica_tools.classification import predict_xr, sklearn_flatten, sklearn_unflatten\n",
    "from deafrica_tools.dask import create_local_dask_cluster\n",
    "from deafrica_tools.datahandling import load_ard\n",
    "from deafrica_tools.plotting import rgb\n",
    "from deafrica_tools.spatial import xr_rasterize\n",
    "from deafrica_tools.temporal import temporal_statistics, xr_phenology\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from feature_extraction import feature_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cd763d-b365-4e1b-88d2-019364ae1de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_local_dask_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539ee71e-008f-4de6-91d1-df693c64b704",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "\n",
    "Get central district and crop mask areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340173f3-2be9-4223-8bcb-42d115b5bcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_boundaries_file = (\n",
    "    \"data/admin-boundaries/GRID3_Zambia_Administrative_Boundaries_Districts_2020.shp\"\n",
    ")\n",
    "\n",
    "admin_boundaries_gdf = gpd.read_file(admin_boundaries_file).to_crs(\"EPSG:6933\")\n",
    "\n",
    "province = \"Central\"\n",
    "province_boundaries_gdf = admin_boundaries_gdf.loc[\n",
    "    admin_boundaries_gdf[\"PROVINCE\"] == province\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35451828-09de-4477-be80-9e49ff26196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "province_boundaries_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf7328b-aaf3-443d-8473-055fea7bdf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "province_gdf = gpd.GeoDataFrame(\n",
    "    {\n",
    "        \"province\": [province],\n",
    "        \"geometry\": province_boundaries_gdf[\"geometry\"].unary_union,\n",
    "    },\n",
    "    crs=province_boundaries_gdf.crs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4645d386-1a30-44ff-8503-ea560d21b925",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "\n",
    "Lazy load data, create central mask, then mask crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91343b78-31d3-4264-b98e-7567ce015f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app=\"crop_type_ml\")\n",
    "\n",
    "# Write a general query\n",
    "time = \"2021\"\n",
    "resolution = (-20, 20)\n",
    "output_crs = \"EPSG:6933\"\n",
    "\n",
    "query = {\n",
    "    \"time\": time,\n",
    "    \"resolution\": resolution,\n",
    "    \"output_crs\": output_crs,\n",
    "    \"dask_chunks\": {\"time\": 1, \"x\": 2000, \"y\": 2000},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fc0b09-ddb6-4e57-bf34-db1beb18fe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_of_interest_gdf = province_boundaries_gdf\n",
    "district_column = \"DISTRICT\"\n",
    "output_prefix = \"data/2021_features_cropmasked\"\n",
    "\n",
    "file_list = []\n",
    "\n",
    "for index, district in area_of_interest_gdf.iterrows():\n",
    "    \n",
    "    district_name = district[district_column]\n",
    "    print(f\"Processing {district_name}\")\n",
    "\n",
    "    # set up query based on polygon\n",
    "    geom = geometry.Geometry(geom=district.geometry, crs=area_of_interest_gdf.crs)\n",
    "    q = {\"geopolygon\": geom}\n",
    "\n",
    "    # merge polygon query with user supplied query params\n",
    "    query.update(q)\n",
    "\n",
    "    # Get the features for every pixel\n",
    "    feature_data = feature_layers(query).squeeze(dim=\"time\", drop=True)\n",
    "    \n",
    "    crop_mask_query = query.copy()\n",
    "    crop_mask_query.update({\"time\": \"2019\"})\n",
    "    \n",
    "    # Load the crop mask\n",
    "    crop_mask = dc.load(\n",
    "        product=\"crop_mask_southeast\",\n",
    "        **crop_mask_query\n",
    "    )\n",
    "    \n",
    "    # Create a mask\n",
    "    district_mask = xr_rasterize(\n",
    "        gdf=gpd.GeoDataFrame({\"DISTRICT\": [district_name], \"geometry\": [district.geometry]}, crs=area_of_interest_gdf.crs),\n",
    "        da=feature_data,\n",
    "        transform=feature_data.geobox.transform,\n",
    "        crs=\"EPSG:6933\",\n",
    "    )\n",
    "    \n",
    "    # Filter to crop pixels within the district\n",
    "    district_crop_data = feature_data.where((crop_mask.filtered == 1) & (district_mask == 1))\n",
    "    \n",
    "    # before reshaping, get list of data variables, which are the names of each feature.\n",
    "    feature_list = list(district_crop_data.data_vars)\n",
    "    \n",
    "    # Reshape to get input for model (array where each row is a pixel\n",
    "    crop_data_for_model = district_crop_data.stack(pixel=(\"y\", \"x\")).load()\n",
    "    print(f\"    Converted to list of pixels. Shape = {crop_data_for_model.to_array().shape}\")\n",
    "    \n",
    "    # Drop all rows containing nan observations\n",
    "    crop_data_for_model = crop_data_for_model.dropna(dim=\"pixel\", how=\"any\")\n",
    "    print(f\"    Dropped pixels containing nans. Shape = {crop_data_for_model.to_array().shape}\")\n",
    "    \n",
    "    # Convert to Xarray Dataarray before converting to Numpy\n",
    "    crop_data_for_model = crop_data_for_model.to_array()\n",
    "    \n",
    "    # Convert to numpy array. Tanspose for use with sklearn\n",
    "    crop_data_for_model = crop_data_for_model.to_numpy()\n",
    "    crop_data_for_model = np.transpose(crop_data_for_model)\n",
    "    \n",
    "    # prepare for pickling\n",
    "    # Output the feature list (containing variable names) and the crop-masked data as a numpy array\n",
    "    output_data = (feature_list, crop_data_for_model)\n",
    "    \n",
    "    #pickle the data for later use\n",
    "    pickle_file = f\"{output_prefix}_{district_name}.pickle\"\n",
    "    file_list.append(pickle_file)\n",
    "\n",
    "    with open(pickle_file, \"wb\") as f:\n",
    "        pickle.dump(output_data, f)\n",
    "        \n",
    "    print(f\"    Size of pickled output: {os.path.getsize(pickle_file)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
